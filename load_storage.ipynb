{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from tools import *\n",
    "from prompts import *\n",
    "Settings.llm = get_llm(model='gpt-4o-mini')\n",
    "Settings.embed_model=get_embed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化客户端\n",
    "db = chromadb.PersistentClient(path=\"./knowledge_base/vector_base\")\n",
    "\n",
    "# 获取 collection\n",
    "chroma_collection = db.get_or_create_collection(\"graph_func_doc\")\n",
    "\n",
    "# 将 chroma 分配为上下文中的 vector_store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 从存储的向量加载你的索引\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")\n",
    "# 配置检索器\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# 配置响应合成器\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    text_qa_template=DUNC_DOC_QA_PROMPT\n",
    ")\n",
    "\n",
    "# 组装查询引擎\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str=\"\"\"\n",
    "Picture this, you're a game tester and you're trying to figure out how players are interacting with each other within a massive multiplayer video game. In the game, each team's communication and collaboration can be represented as a graph, where each player is a node and the communication between them is an edge. You use this graph to investigate the real-time strategy (RTS) squad communication patterns. To understand this communication graph better, you decide to see if there are any distinct communities within the whole player network. You have with you a graph of the details saved in a file called 'copenhagen.gml', taken from the comprehensive Copenhagen Networks Study.\\n\\nTo do this, you choose to use two popular community detection algorithms - Louvain and Der - to figure out if there are any trends of players forming specific communities. However, simple detection isn't enough. You also want to understand the characteristics of these communities, such as their size and internal_edge_density, which mirrors the intensity or frequency of interactions within the communities. \\n\\nThe challenge here lies in comparing and visualizing the results from both algorithms: you want to visualize the relation between the community size and the internal_edge_density from the two different algorithms using \\\"plot_com_properties_relation\\\" function. This way you could easily understand how these communities vary and behave in terms of their size and density of communication.\n",
    "\"\"\"\n",
    "# response = query_engine.query(f\"\"\"\n",
    "# 你是一个文档提取器，精通精通基础图论、图统计学习和图嵌入三个方面的知识\n",
    "# 你需要根据问题{query_str}来帮我抽取出他可能需要使用到的文档,重点观察文档中使用到的函数或者算法\n",
    "\n",
    "# \"\"\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgentWorker\n",
    "llm=get_llm(model='gpt-4o-mini')\n",
    "tools=get_tools()\n",
    "react_worker = ReActAgentWorker.from_tools(\n",
    "    tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "agent=react_worker.as_agent()\n",
    "res=agent.chat(f\"\"\"\n",
    "你是一个文档提取器，精通精通基础图论、图统计学习和图嵌入三个方面的知识\n",
    "你需要根据问题{query_str}来帮我抽取出他可能需要使用到的文档\n",
    "重点观察文档中使用到的函数或者算法\n",
    "函数一般含有_,算法开头一般是大写\n",
    "最后你需要按json格式给出答案，包含所有文档\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMPllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
